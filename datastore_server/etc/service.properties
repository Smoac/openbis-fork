# The root directory of the data store
storeroot-dir = targets/store

# Port
port = 8889

# Session timeout in minutes
session-timeout = 30

# Path to the keystore
keystore.path = dist/etc/openBIS.keystore

# Password of the keystore
keystore.password = changeit

# Key password of the keystore
keystore.key-password = changeit

# The check interval (in seconds)
check-interval = 5

# The time-out for clean up work in the shutdown sequence (in seconds).
# Note that that the maximal time for the shutdown sequence to complete can be as large 
# as twice this time.
shutdown-timeout = 2

# If free disk space goes below value defined here, a notification email will be sent.
# Value must be specified in kilobytes (1048576 = 1024 * 1024 = 1GB). If no high water mark is
# specified or if value is negative, the system will not be watching.
highwater-mark = 1048576

# If a data set is successfully registered it sends out an email to the registrator. 
# If this property is not specified, no email is sent to the registrator. This property
# does not affect the mails which are sent, when the data set could not be registered.
notify-successful-registration = false

# The URL of the openBIS server
server-url = http://localhost:8080/openbis

# The username to use when contacting the openBIS server
username = etlserver

# The password to use when contacting the openBIS server
password = doesnotmatter

# SMTP properties (must start with 'mail' to be considered).
# mail.smtp.host = localhost
# mail.from = datastore_server@localhost
# mail.smtp.user = 
# mail.smtp.password = 

# Maximum number of retries if renaming failed.
# renaming.failure.max-retries = 12

# The number of milliseconds to wait before retrying to execute the renaming process.
# renaming.failure.millis-to-sleep = 5000

# Globally used separator character which separates entities in a data set file name 
data-set-file-name-entity-separator = _

# Prefixes for processing paths for all procedure types. 
# default-prefix-for-absolute-paths is the key for paths starting with '/'.
# default-prefix-for-relative-paths is the key for paths not starting with '/'.
#
default-prefix-for-absolute-paths = 

# Processors of processing instructions.
#
# processors: comma separated list of procedure type codes
# processor.<procedure type code>.prefix-for-absolute-paths: Key for a processing path starting with '/'.
# processor.<procedure type code>.prefix-for-relative-paths: Key for a processing path not starting with '/'.
# processor.<procedure type code>.parameters-file: Name of the file containing the processing parameters.
# processor.<procedure type code>.finished-file-template: Name of the marker file which finishes processing.

processors = DATA_ACQUISITION
processor.DATA_ACQUISITION.prefix-for-absolute-paths = ${default-prefix-for-absolute-paths}
processor.DATA_ACQUISITION.prefix-for-relative-paths = targets/processing
processor.DATA_ACQUISITION.parameters-file = parameters
processor.DATA_ACQUISITION.data-set-code-prefix-glue = ${data-set-file-name-entity-separator}
processor.DATA_ACQUISITION.finished-file-template = .MARKER_is_finished_{0}
processor.DATA_ACQUISITION.input-storage-format = BDS_DIRECTORY
# time after which the copy of a single file for processing should complete. 
# If that will not happen, operation will be terminated and relaunched. 
processor.DATA_ACQUISITION.data-copy-timeout = 10

# Comma separated names of processing threads. Each thread should have configuration properties prefixed with its name.
# E.g. 'code-extractor' property for the thread 'my-etl' should be specified as 'my-etl.code-extractor'
inputs=main-thread

# ---------------------------------------------------------------------------
# 'main-thread' thread configuration
# ---------------------------------------------------------------------------

# The directory to watch for incoming data.
main-thread.incoming-dir = targets/incoming
# The group the samples extracted by this thread belong to. If commented out or empty, then samples
# are considered associated to a database instance (not group private). 
# main-thread.group-code = CISD

# The store format that should be applied in the incoming directory.
main-thread.incoming-dir.format = 

# ---------------- Plugin properties

# The extractor plugin class to use for code extraction
main-thread.data-set-info-extractor = ch.systemsx.cisd.etlserver.DefaultDataSetInfoExtractor
# Separator used to extract the barcode in the data set file name
main-thread.data-set-info-extractor.entity-separator = ${data-set-file-name-entity-separator}

main-thread.type-extractor = ch.systemsx.cisd.etlserver.SimpleTypeExtractor
main-thread.type-extractor.file-format-type = TIFF
main-thread.type-extractor.locator-type = RELATIVE_LOCATION
main-thread.type-extractor.data-set-type = HCS_IMAGE
main-thread.type-extractor.procedure-type = DATA_ACQUISITION
# Location of file containing data set properties 
#main-thread.type-extractor.data-set-properties-file = etc/data-set.properties

# The storage processor (IStorageProcessor implementation)
#main-thread.storage-processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor
main-thread.storage-processor = ch.systemsx.cisd.etlserver.BDSStorageProcessor
main-thread.storage-processor.version = 1.1
main-thread.storage-processor.sampleTypeCode = CELL_PLATE
main-thread.storage-processor.sampleTypeDescription = Screening Plate
main-thread.storage-processor.format = HCS_IMAGE V1.0
main-thread.storage-processor.number_of_channels = 2
main-thread.storage-processor.contains_original_data = TRUE
main-thread.storage-processor.well_geometry = 3x3
main-thread.storage-processor.file-extractor = ch.systemsx.cisd.etlserver.imsb.HCSImageFileExtractor
