# Unique code of this Data Store Server. Not more than 40 characters.
data-store-server-code = my-dss

# The root directory of the data store
storeroot-dir = targets/store

# Port
port = 8889

# Session timeout in minutes
session-timeout = 30

# Path to the keystore
keystore.path = dist/etc/openBIS.keystore

# Password of the keystore
keystore.password = changeit

# Key password of the keystore
keystore.key-password = changeit

# The check interval (in seconds)
check-interval = 3

# The time-out for clean up work in the shutdown sequence (in seconds).
# Note that that the maximal time for the shutdown sequence to complete can be as large 
# as twice this time.
shutdown-timeout = 2

# If a data set is successfully registered it sends out an email to the registrator. 
# If this property is not specified, no email is sent to the registrator. This property
# does not affect the mails which are sent, when the data set could not be registered.
notify-successful-registration = false

# The URL of the openBIS server
server-url = http://localhost:8888/openbis

# The username to use when contacting the openBIS server
username = etlserver_yeastx

# The password to use when contacting the openBIS server
password = doesnotmatter

# The base URL for Web client access.
download-url = https://localhost:8889

# The period of no write access that needs to pass before an incoming data item is considered 
# complete and ready to be processed (in seconds) [default: 300]. 
# Valid only when auto-detection method is used to determine if an incoming data are ready to be processed.
quiet-period = 3

# Specifies what should happen if an error occurs during dataset processing. 
# By default this flag is set to false and user has to modify the 'faulty paths file' 
# each time the faulty dataset should be processed again.
# Set this flag to true if the processing should be repeated after some time without any manual intervention.
reprocess-faulty-datasets = true

#mail.smtp.host = smtp0.ethz.ch
# TODO change this, just for tests !!!!!!!!
mail.smtp.host = file:///Users/tpylak/main/tmp
mail.from = openbis@imsb-us-openbis.ethz.ch
mail.smtp.user = 
mail.smtp.password = 

# Comma separated names of processing threads. Each thread should have configuration properties prefixed with its name.
# E.g. 'code-extractor' property for the thread 'my-etl' should be specified as 'my-etl.code-extractor'
inputs=main-thread, eicml-uploader, fiaml-uploader

# Globally used separator character which separates entities in a data set file name 
data-set-file-name-entity-separator = .

# ---------------------------------------------------------------------------
# 'main-thread' thread configuration
# ---------------------------------------------------------------------------

# The directory to watch for incoming data.
main-thread.incoming-dir = targets/incoming

# Determines when the incoming data should be considered complete and ready to be processed.
# Allowed values: 
#  - auto-detection - when no write access will be detected for a specified 'quite-period'
#  - marker-file		- when an appropriate marker file for the data exists. 
# The default value is 'marker-file'.
main-thread.incoming-data-completeness-condition = auto-detection
main-thread.incoming-dir.format = 

sample-name-property-code = samplename
experiment-name-property-code = name

yeastx-databaseEngineCode = postgresql
yeastx-basicDatabaseName = metabol
yeastx-databaseKind = productive

main-thread.dataset-handler = ch.systemsx.cisd.yeastx.etl.BatchDataSetHandler
main-thread.dataset-handler.unique-sample-name-property-code = ${sample-name-property-code}
main-thread.dataset-handler.unique-experiment-name-property-code = ${experiment-name-property-code}

# The extractor class to use for code extraction
main-thread.data-set-info-extractor = ch.systemsx.cisd.yeastx.etl.BatchDataSetInfoExtractor
main-thread.data-set-info-extractor.unique-sample-name-property-code = ${sample-name-property-code}
main-thread.data-set-info-extractor.unique-experiment-name-property-code = ${experiment-name-property-code}

# The extractor class to use for type extraction
main-thread.type-extractor = ch.systemsx.cisd.yeastx.etl.TypeExtractorYeastX

# The storage processor (IStorageProcessor implementation)
main-thread.storage-processor = ch.systemsx.cisd.yeastx.etl.StorageProcessorWithDropboxes
# TODO decide: create a directory !!!!!!
main-thread.storage-processor.eicml-dropbox-dir = targets/dropbox1
main-thread.storage-processor.fiaml-dropbox-dir = targets/dropbox2
main-thread.storage-processor.entity-separator = .
main-thread.storage-processor.processor = ch.systemsx.cisd.yeastx.etl.StorageProcessorWithMLUploader
main-thread.storage-processor.processor.unique-sample-name-property-code = ${sample-name-property-code}
main-thread.storage-processor.processor.unique-experiment-name-property-code = ${experiment-name-property-code}
main-thread.storage-processor.processor.database.databaseEngineCode = ${yeastx-databaseEngineCode}
main-thread.storage-processor.processor.database.basicDatabaseName = ${yeastx-basicDatabaseName}
main-thread.storage-processor.processor.database.databaseKind = ${yeastx-databaseKind}
main-thread.storage-processor.processor.database.readOnlyGroup = metabol_readonly
main-thread.storage-processor.processor.database.readWriteGroup = metabol_readwrite
# TODO decide: change in production !!!!!!
main-thread.storage-processor.processor.database.scriptFolder = source/sql
main-thread.storage-processor.processor.processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor

# ---------------------------------------------------------------------------
# plugin properties for the thread which uploads eicML files
# ---------------------------------------------------------------------------

# The directory to watch for incoming data.
# TODO change this, just for tests !!!!!!!!
eicml-uploader.incoming-dir = targets/dropbox1-out
eicml-uploader.incoming-data-completeness-condition = auto-detection
eicml-uploader.incoming-dir.format = 


# The extractor class to use for code extraction
eicml-uploader.data-set-info-extractor = ch.systemsx.cisd.etlserver.DefaultDataSetInfoExtractor
eicml-uploader.data-set-info-extractor.index-of-sample-code = 0
eicml-uploader.data-set-info-extractor.index-of-group-code = 1
eicml-uploader.data-set-info-extractor.index-of-parent-data-set-code = 2
eicml-uploader.data-set-info-extractor.entity-separator = ${data-set-file-name-entity-separator}

# The extractor class to use for type extraction
eicml-uploader.type-extractor = ch.systemsx.cisd.yeastx.etl.TypeExtractorYeastX
eicml-uploader.type-extractor.file-format-type = XML
eicml-uploader.type-extractor.locator-type = RELATIVE_LOCATION
eicml-uploader.type-extractor.data-set-type = EICML
eicml-uploader.type-extractor.is-measured = false

# The storage processor which uploads the content of the files to the additional database
eicml-uploader.storage-processor = ch.systemsx.cisd.yeastx.etl.StorageProcessorWithMLUploader
eicml-uploader.storage-processor.unique-sample-name-property-code = ${sample-name-property-code}
eicml-uploader.storage-processor.unique-experiment-name-property-code = ${experiment-name-property-code}
eicml-uploader.storage-processor.database.databaseEngineCode = ${yeastx-databaseEngineCode}
eicml-uploader.storage-processor.database.basicDatabaseName = ${yeastx-basicDatabaseName}
eicml-uploader.storage-processor.database.databaseKind = ${yeastx-databaseKind}
eicml-uploader.storage-processor.processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor

# ---------------- plugin properties for the thread which uploads fiaML files

# The directory to watch for incoming data.
# TODO change this, just for tests !!!!!!!!
fiaml-uploader.incoming-dir = targets/dropbox2-out
fiaml-uploader.incoming-data-completeness-condition = auto-detection
fiaml-uploader.incoming-dir.format = 


# The extractor class to use for code extraction
fiaml-uploader.data-set-info-extractor = ch.systemsx.cisd.etlserver.DefaultDataSetInfoExtractor
fiaml-uploader.data-set-info-extractor.index-of-sample-code = 0
fiaml-uploader.data-set-info-extractor.index-of-group-code = 1
fiaml-uploader.data-set-info-extractor.index-of-parent-data-set-code = 2
fiaml-uploader.data-set-info-extractor.entity-separator = ${data-set-file-name-entity-separator}

# The extractor class to use for type extraction
fiaml-uploader.type-extractor = ch.systemsx.cisd.yeastx.etl.TypeExtractorYeastX
fiaml-uploader.type-extractor.file-format-type = XML
fiaml-uploader.type-extractor.locator-type = RELATIVE_LOCATION
fiaml-uploader.type-extractor.data-set-type = FIAML
fiaml-uploader.type-extractor.is-measured = false

# The storage processor which uploads the content of the files to the additional database
fiaml-uploader.storage-processor = ch.systemsx.cisd.yeastx.etl.StorageProcessorWithMLUploader
fiaml-uploader.storage-processor.unique-sample-name-property-code = ${sample-name-property-code}
fiaml-uploader.storage-processor.unique-experiment-name-property-code = ${experiment-name-property-code}
fiaml-uploader.storage-processor.database.databaseEngineCode = ${yeastx-databaseEngineCode}
fiaml-uploader.storage-processor.database.basicDatabaseName = ${yeastx-basicDatabaseName}
fiaml-uploader.storage-processor.database.databaseKind = ${yeastx-databaseKind}
fiaml-uploader.storage-processor.processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor