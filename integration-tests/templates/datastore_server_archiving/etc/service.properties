# Unique code of this Data Store Server. Not more than 40 characters.
data-store-server-code = DSS-ARCHIVING

root-dir=..
# The root directory of the data store
storeroot-dir = ${root-dir}/data/main-store

# The directory where the command queue file is located; defaults to storeroot-dir 
commandqueue-dir =

# Port
port = 8444

# Session timeout in minutes
session-timeout = 30

# Path to the keystore
keystore.path = etc/openBIS.keystore

# Password of the keystore
keystore.password = changeit

# Key password of the keystore
keystore.key-password = changeit

# The check interval (in seconds)
check-interval = 2

# The time-out for clean up work in the shutdown sequence (in seconds).
# Note that that the maximal time for the shutdown sequence to complete can be as large 
# as twice this time.
shutdown-timeout = 2

# The period of no write access that needs to pass before an incoming data item is considered 
# complete and ready to be processed (in seconds) [default: 300]. 
# Valid only when auto-detection method is used to determine if an incoming data are ready to be processed.
quiet-period = 5


# If free disk space goes below value defined here, a notification email will be sent.
# Value must be specified in kilobytes (1048576 = 1024 * 1024 = 1GB). If no high water mark is
# specified or if value is negative, the system will not be watching.
highwater-mark = 1048576

# The URL of the LIMS server
server-url = https://localhost:8443/openbis/openbis

# The username to use when contacting the LIMS server
username = etlserver1

# The password to use when contacting the LIMS server
password = <change this>

# The base URL for Web client access.
download-url = https://localhost:8444

# SMTP properties (must start with 'mail' to be considered).
mail.smtp.host = file://${root-dir}/email
mail.from = datastore_server@localhost
mail.smtp.user = 
mail.smtp.password = 


# Maximum number of retries if renaming failed.
# renaming.failure.max-retries = 12

# The number of milliseconds to wait before retrying to execute the renaming process.
# renaming.failure.millis-to-sleep = 5000

# Globally used separator character which separates entities in a data set file name 
data-set-file-name-entity-separator = _

# Comma separated names of processing threads. Each thread should have configuration properties prefixed with its name
# E.g. 'code-extractor' property for the thread 'my-etl' should be specified as 'my-etl.code-extractor'
inputs=jython-dropbox


jython-dropbox.incoming-dir = ${root-dir}/data/incoming-jython
jython-dropbox.top-level-data-set-handler = ch.systemsx.cisd.etlserver.registrator.JythonTopLevelDataSetHandler
jython-dropbox.incoming-data-completeness-condition = auto-detection
jython-dropbox.strip-file-extension = true
jython-dropbox.storage-processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor
jython-dropbox.script-path = ${root-dir}/data-archiving/scripts/jython-dropbox.py

# ---------------------------------------------------------------------------
# (optional) archiver configuration
# ---------------------------------------------------------------------------

# Configuration of an archiver task. All properties are prefixed with 'archiver.'.

archiver.class = ch.systemsx.cisd.openbis.dss.generic.server.plugins.standard.RsyncArchiver
archiver.destination = localhost:/tmp/integration-tests/archiving/rsync-archive
 


# Comma separated names of maintenance plugins.  
# Each plugin should have configuration properties prefixed with its name.
# Mandatory properties for each <plugin> include: 
#   <plugin>.class - Fully qualified plugin class name
#   <plugin>.interval - The time between plugin executions (in seconds)
# Optional properties for each <plugin> include:
#   <plugin>.start - Time of the first execution (HH:mm)
#   <plugin>.execute-only-once - If true the task will be executed exactly once, 
#                                interval will be ignored. By default set to false.
maintenance-plugins = auto-archiver

# Performs automatic archivization of 'AVAILABLE' data sets based on their properties
auto-archiver.class = ch.systemsx.cisd.etlserver.plugins.AutoArchiverTask
# The time between subsequent archive operations (in seconds)
auto-archiver.interval = 10
auto-archiver.remove-datasets-from-store=false
auto-archiver.older-than=0

