# Unique code of this Data Store Server. Not more than 40 characters.
data-store-server-code = dss-screening

# host name of the machine on which the datastore server is running
host-address = https://localhost

# parent directory of the store directory and all the dropboxes
root-dir = data
ibrain2-root = ${root-dir}/dropboxes

# The root directory of the data store
storeroot-dir = ${root-dir}/store

# The directory where the command queue file is located; defaults to storeroot-dir 
commandqueue-dir =

# Port
port = 8444
use-ssl = true

# Session timeout in minutes
session-timeout = 720

# Path to the keystore
keystore.path = etc/openBIS.keystore
# Password of the keystore
keystore.password = changeit
# Key password of the keystore
keystore.key-password = changeit

# The check interval (in seconds)
check-interval = 5

# The time-out for clean up work in the shutdown sequence (in seconds).
# Note that that the maximal time for the shutdown sequence to complete can be as large 
# as twice this time.
# Remark: On a network file system, it is not recommended to turn this value to something 
# lower than 180.
shutdown-timeout = 180

# If free disk space goes below value defined here, a notification email will be sent.
# Value must be specified in kilobytes (1048576 = 1024 * 1024 = 1GB). If no high water mark is
# specified or if value is negative, the system will not be watching.
highwater-mark = -1

# If a data set is successfully registered it sends out an email to the registrator. 
# If this property is not specified, no email is sent to the registrator. This property
# does not affect the mails which are sent, when the data set could not be registered.
notify-successful-registration = false

# The URL of the openBIS server
server-url = ${host-address}:8443

# The username to use when contacting the openBIS server
username = etlserver

# The password for the etlserver user who contacts the openBIS server
password = etlserver_password

# The base URL for Web client access to the data store server.
download-url = ${host-address}:${port}

# SMTP properties (must start with 'mail' to be considered).
# The current configuration saves the emails in the file system in the root directory 
mail.smtp.host = file://${root-dir}
# mail.smtp.host = localhost
# mail.from = datastore_server@ethz.ch
# mail.smtp.user = 
# mail.smtp.password = 

# ---------------------------------------------------------------------------
# (optional) archiver configuration
# ---------------------------------------------------------------------------

# Configuration of an archiver task. All properties are prefixed with 'archiver.'.

# Archiver class specification (together with the list of packages this class belongs to).
#archiver.class = ch.systemsx.cisd.openbis.dss.generic.server.plugins.demo.DemoArchiver

# ---------------------------------------------------------------------------
#                      INTERNAL CONFIGURATION, 
# Do not change this part unless you are developing openBIS extensions.
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# screening database specification
# ---------------------------------------------------------------------------

data-sources = imaging-db
imaging-db.version-holder-class = ch.systemsx.cisd.openbis.dss.etl.ImagingDatabaseVersionHolder
imaging-db.databaseEngineCode = postgresql
imaging-db.basicDatabaseName = imaging
imaging-db.databaseKind = biozentrum_integration_tests
imaging-db.scriptFolder = sql/imaging
imaging-db.owner =
imaging-db.password = 
# Credentials of a database user which is able to create a new database or roles in it.
# Leave empty to use the db engines defaults.
# Used only during the first start of the server or when server is upgraded to a new version.
imaging-db.adminUser = 
imaging-db.adminPassword =

# ---------------------------------------------------------------------------
# reporting and processing plugins configuration
# ---------------------------------------------------------------------------

# Comma separated names of reporting plugins. Each plugin should have configuration properties prefixed with its name.
reporting-plugins =  default-plate-image-analysis, plate-image-analysis-graph

default-plate-image-analysis.label = Image Analysis Results
default-plate-image-analysis.dataset-types = HCS_ANALYSIS_WELL_FEATURES
default-plate-image-analysis.class = ch.systemsx.cisd.openbis.dss.generic.server.plugins.ImageAnalysisMergedRowsReportingPlugin
default-plate-image-analysis.properties-file =

plate-image-analysis-graph.label = Image Analysis Graphs
plate-image-analysis-graph.dataset-types = HCS_ANALYSIS_WELL_FEATURES
plate-image-analysis-graph.class = ch.systemsx.cisd.openbis.dss.generic.server.plugins.ImageAnalysisGraphReportingPlugin
plate-image-analysis-graph.servlet-path = datastore_server_graph/
plate-image-analysis-graph.properties-file = etc/tabular-data-graph.properties

# ---------------------------------------------------------------------------
# screening specific extension servlets 
# ---------------------------------------------------------------------------

# list of additional web servlets which will be exposed
plugin-services = screening-image-download-servlet, tabular-data-graph-servlet, screening-dss-api-exporter-servlet

# class of the web servlet
screening-image-download-servlet.class = ch.systemsx.cisd.openbis.dss.generic.server.MergingImagesDownloadServlet
# URL which will be mapped to this servlet
screening-image-download-servlet.path = /datastore_server_screening/*

tabular-data-graph-servlet.class = ch.systemsx.cisd.openbis.dss.generic.server.TabularDataGraphServlet
tabular-data-graph-servlet.path = /datastore_server_graph/*
tabular-data-graph-servlet.properties-file = etc/tabular-data-graph.properties

# expose an DSS API interface with RPC
screening-dss-api-exporter-servlet.class = ch.systemsx.cisd.openbis.dss.generic.server.DssScreeningApiServlet
screening-dss-api-exporter-servlet.path = /rmi-datastore-server-screening-api-v1/*

# ---------------------------------------------------------------------------
# image overview plugins configuration
# ---------------------------------------------------------------------------

# Comma separated names of image overview plugins. 
# Each plugin should have configuration properties prefixed with its name.
# Generic properties for each <plugin> include: 
#   <plugin>.class   - Fully qualified plugin class name (mandatory).
#   <plugin>.default - If true all data set types not handled by other plugins should be handled 
#                      by the plugin (default = false). 
#   <plugin>.dataset-types - Comma separated list of data set types handled by the plugin 
#                      (optional and ignored if default is true, otherwise mandatory). 
overview-plugins = microscopy-image-overview

microscopy-image-overview.class = ch.systemsx.cisd.openbis.dss.generic.server.MergingImagesDownloadServlet
microscopy-image-overview.dataset-types = MICROSCOPY_IMAGE

# ---------------------------------------------------------------------------

maintenance-plugins=data-set-clean-up, post-registration

# Removes data sets deleted from openBIS also from imaging database
data-set-clean-up.class = ch.systemsx.cisd.etlserver.plugins.DeleteFromExternalDBMaintenanceTask
# specified in seconds. Here : every day
data-set-clean-up.interval = 86400
data-set-clean-up.data-source = imaging-db

# This maintenance task ensures that the datasets are moved to the "extension share" quickly 
# after the registration. When a dataset is moved a confirmation file is created.
post-registration.class = ch.systemsx.cisd.etlserver.postregistration.PostRegistrationMaintenanceTask
post-registration.interval = 5
post-registration.cleanup-tasks-folder = cleanup-tasks
post-registration.ignore-data-sets-before-date = 2011-08-08
post-registration.last-seen-data-set-file = ${root-dir}/last-seen-data-set-notification-db.dat
post-registration.post-registration-tasks = eager-shuffling, notifying
post-registration.eager-shuffling.class = ch.systemsx.cisd.etlserver.postregistration.EagerShufflingTask
post-registration.eager-shuffling.data-store-server-code = ${data-store-server-code}
post-registration.eager-shuffling.storeroot-dir = ${storeroot-dir}
post-registration.eager-shuffling.share-finder.class = ch.systemsx.cisd.etlserver.postregistration.SimpleShareFinder
post-registration.notifying.class = ch.systemsx.cisd.etlserver.postregistration.NotifyingTask
post-registration.notifying.message-template = storage_provider.storage.status = STORAGE_SUCCESSFUL\n\
storage_provider.dataset.id = ${data-set-code}\n\
ibrain2.dataset.id = ${property:ibrain2.dataset.id}
post-registration.notifying.destination-path-template = ${ibrain2-root}/registration-status/ibrain2_dataset_id_${property:ibrain2.dataset.id}.properties

# ---------------------------------------------------------------------------
#                      DROPBOXES CONFIGURATION 
# ---------------------------------------------------------------------------

# The period of no write access that needs to pass before an incoming data item is considered 
# complete and ready to be processed (in seconds) [default: 300]. 
# Valid only when auto-detection method is used to determine if an incoming data are ready to be processed.
quiet-period = 5

inputs = hcs_image_raw, hcs_image_overview, hcs_image_segmentation, hcs_analysis_well_results_summaries, hcs_analysis_well_quality_summary, hcs_analysis_cell_features_cc_mat, api_hcs_analysis_well_classification_summaries, api_default

scripts-dir = ${ibrain2-root}/scripts
ibrain2-dropboxes-dir = ${ibrain2-root}/incoming
staging-dir = ${ibrain2-root}/tmp

# --------- abstract common dropbox properties ------------
# auto-detection
abstract-common-ibrain2-dropbox.incoming-data-completeness-condition = marker-file
abstract-common-ibrain2-dropbox.top-level-data-set-handler = ch.systemsx.cisd.openbis.dss.etl.jython.JythonPlateDataSetHandler
abstract-common-ibrain2-dropbox.staging-dir = ${staging-dir}
abstract-common-ibrain2-dropbox.storage-processor.data-source = imaging-db

# --------------------- image dropboxes ----------------------------------------------
# --------- abstract common hcs_image_* dropbox properties ---------------------------
abstract-image-ibrain2-dropbox. = abstract-common-ibrain2-dropbox.
abstract-image-ibrain2-dropbox.storage-processor = ch.systemsx.cisd.openbis.dss.etl.PlateStorageProcessor
# Optional boolean property, true by default. 
# If true an email is sent if some images for the uploaded plate are missing. 
abstract-image-ibrain2-dropbox.storage-processor.notify-if-incomplete = false
# -------------
hcs_image_raw. = abstract-image-ibrain2-dropbox.
hcs_image_raw.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_IMAGE_RAW
hcs_image_raw.script-path = ${scripts-dir}/hcs_image_raw.py
# -------------
hcs_image_overview. = abstract-image-ibrain2-dropbox.
hcs_image_overview.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_IMAGE_OVERVIEW
hcs_image_overview.script-path = ${scripts-dir}/hcs_image_overview.py
# -------------
hcs_image_segmentation. = abstract-image-ibrain2-dropbox.
hcs_image_segmentation.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_IMAGE_SEGMENTATION
hcs_image_segmentation.script-path = ${scripts-dir}/hcs_image_segmentation.py

# --------------------- well analysis dropboxes --------------------------------------
# --------- abstract common hcs_analysis_well_* dropbox properties -------------------
abstract-analysis-dropbox. =  abstract-common-ibrain2-dropbox.
abstract-analysis-dropbox.storage-processor = ch.systemsx.cisd.openbis.dss.etl.featurevector.FeatureVectorStorageProcessor
abstract-analysis-dropbox.storage-processor.processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor
# --------------
hcs_analysis_well_quality_summary. =  abstract-analysis-dropbox.
hcs_analysis_well_quality_summary.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_ANALYSIS_WELL_QUALITY_SUMMARY
hcs_analysis_well_quality_summary.script-path = ${scripts-dir}/hcs_analysis_well_quality_summary.py
# --------------
hcs_analysis_well_results_summaries. = abstract-analysis-dropbox.
hcs_analysis_well_results_summaries.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_ANALYSIS_WELL_RESULTS_SUMMARIES
hcs_analysis_well_results_summaries.script-path = ${scripts-dir}/hcs_analysis_well_results_summaries.py

# --------------------- black-box dropboxes ------------------------------------------
# --------------------- abstract common black-box dropbox properties -----------------
abstract-black-box-ibrain2-dropbox. = abstract-common-ibrain2-dropbox.
abstract-black-box-ibrain2-dropbox.storage-processor = ch.systemsx.cisd.etlserver.DefaultStorageProcessor
# --------------
hcs_analysis_cell_features_cc_mat. = abstract-black-box-ibrain2-dropbox.
hcs_analysis_cell_features_cc_mat.incoming-dir = ${ibrain2-dropboxes-dir}/HCS_ANALYSIS_CELL_FEATURES_CC_MAT
hcs_analysis_cell_features_cc_mat.script-path = ${scripts-dir}/hcs_analysis_cell_features_cc_mat.py

# --------------------- API dataset upload dropboxex ------------------------------------------

# default dropbox used when datasets are uploaded with the API 
dss-rpc.put-default = api_default
# temporary folder 
rpc-incoming-dir = ${staging-dir}

# -------------- dropbox for uploading datasets of HCS_ANALYSIS_WELL_RESULTS_SUMMARIES type with the API
dss-rpc.put.HCS_ANALYSIS_WELL_CLASSIFICATION_SUMMARIES = api_hcs_analysis_well_classification_summaries

api_hcs_analysis_well_classification_summaries. =  abstract-analysis-dropbox.
api_hcs_analysis_well_classification_summaries.incoming-dir = ${ibrain2-dropboxes-dir}/API_HCS_ANALYSIS_WELL_CLASSIFICATION_SUMMARIES
api_hcs_analysis_well_classification_summaries.script-path = ${scripts-dir}/api_hcs_analysis_well_classification_summaries.py
# --------------
api_default. = abstract-black-box-ibrain2-dropbox.
api_default.incoming-dir = ${ibrain2-dropboxes-dir}/API_DEFAULT
api_default.script-path = ${scripts-dir}/api_default.py 
